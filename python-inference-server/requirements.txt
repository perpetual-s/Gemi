# Gemi Inference Server Requirements
# Python 3.9+ required

# Core dependencies
fastapi==0.115.5
uvicorn[standard]==0.32.1
python-multipart==0.0.12  # For file uploads
sse-starlette==2.1.3  # For streaming responses

# ML dependencies
torch==2.5.1  # Latest version with MPS support
torchvision==0.20.1
transformers>=4.53.0  # Required for Gemma 3n support
accelerate==1.2.1  # For model optimization
sentencepiece==0.2.0  # Required by Gemma tokenizer
protobuf==5.29.2  # Required by sentencepiece

# Image processing
Pillow==11.0.0

# Audio processing (for future use)
soundfile==0.12.1
librosa==0.10.2.post1

# Utilities
python-dotenv==1.0.1  # For environment variables
aiofiles==24.1.0  # For async file operations
numpy<2.0  # Pin to 1.x for compatibility